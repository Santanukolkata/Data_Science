{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  \n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']  \n",
    "dataset = pd.read_csv(url, names=names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# As was the case with PCA, we need to perform feature scaling for LDA too. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()  \n",
    "\n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test  = sc.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Performing LDA\n",
    "# It requires only four lines of code to perform LDA with Scikit-Learn. \n",
    "# The LinearDiscriminantAnalysis class of the sklearn.discriminant_analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=2)  \n",
    "\n",
    "X_train = lda.fit_transform(X_train, y_train)  \n",
    "X_test  = lda.transform(X_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the LinearDiscriminantAnalysis class is imported as LDA. \n",
    "\n",
    "Like PCA, we have to pass the value for the n_components parameter of the LDA, \n",
    "which refers to the number of linear discriminates that we want to retrieve. \n",
    "\n",
    "In this case we set the n_components to 1, since we first want to check the performance of \n",
    "our classifier with a single linear discriminant. \n",
    "\n",
    "Finally we execute the fit and transform methods to actually retrieve the linear discriminants.\n",
    "\n",
    "Notice, in case of LDA, the transform method takes two parameters: \n",
    "\n",
    "the X_train and the y_train. \n",
    "\n",
    "However in the case of PCA, the transform method only requires one parameter i.e. X_train. \n",
    "\n",
    "This reflects the fact that LDA takes the output class labels into account while \n",
    "selecting the linear discriminants, while PCA doesn't depend upon the output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "classifier.fit(X_train, y_train)  \n",
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm) \n",
    "\n",
    "print('Accuracy ' + str(accuracy_score(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# with one linear discriminant, the algorithm achieved an accuracy of 100%, \n",
    "# which is greater than the accuracy achieved with one principal component, which was 93.33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
