{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3not_relevant</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>31</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  623495513     True      golden                  10               NaN   \n",
       "1  623495514     True      golden                  12               NaN   \n",
       "\n",
       "  sentiment  sentiment:confidence                            date  \\\n",
       "0         3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
       "1         3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
       "\n",
       "             id            query sentiment_gold  \\\n",
       "0  5.400000e+17  #AAPL OR @Apple  3not_relevant   \n",
       "1  5.400000e+17  #AAPL OR @Apple             31   \n",
       "\n",
       "                                                text  \n",
       "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
       "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apple_tweets=pd.read_csv('Apple-Twitter-Sentiment-DFE.csv')\n",
    "df_apple_tweets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3886, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apple_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
       "       '_last_judgment_at', 'sentiment', 'sentiment:confidence', 'date', 'id',\n",
       "       'query', 'sentiment_gold', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apple_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#AAPL:The 10 best Steve Jobs emails ever...http://t.co/82G1kL94tx',\n",
       "       'RT @JPDesloges: Why AAPL Stock Had a Mini-Flash Crash Today $AAPL #aapl http://t.co/hGFcjYa0E9',\n",
       "       'My cat only chews @apple cords. Such an #AppleSnob.', ...,\n",
       "       '@marcbulandr I could not agree more. Between @Apple @Twitter and @IBMWatson only great things will happen. #AppleandIBM #IBMandTwitter',\n",
       "       \"My iPhone 5's photos are no longer downloading automatically to my laptop when I sync it. @apple support is unhelpful. Any ideas?\",\n",
       "       \"RT @SwiftKey: We're so excited to be named to @Apple's 'App Store Best of 2014' list this year! http://t.co/d7qlmti4Uf #Apple\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apple_tweets['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    stopwords = set([word.lower().strip() for word in open(\"nltk_stopwords.txt\", \"rt\").readlines()])\n",
    "    temp = text.split() # Split the text on whitespace\n",
    "    text_words = []\n",
    "\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    #Keep #tags and @mentions\n",
    "    punctuation.remove(\"#\")\n",
    "    punctuation.remove(\"@\")\n",
    "    \n",
    "    for word in temp:\n",
    "        # Remove any punctuation characters present in the beginning of the word\n",
    "        while len(word) > 0 and word[0] in punctuation:\n",
    "            word = word[1:]\n",
    "\n",
    "        # Remove any punctuation characters present in the end of the word\n",
    "        while len(word) > 0 and word[-1] in punctuation:\n",
    "            word = word[:-1]\n",
    "\n",
    "        # Simple rule to eliminate (most) URLs\n",
    "        if len(word) > 0 and \"/\" not in word:\n",
    "            # If it's not a stopword\n",
    "            if word.lower() not in stopwords:\n",
    "                # Append this word into our list of words.\n",
    "                text_words.append(word.lower())\n",
    "        \n",
    "    return text_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#aapl:the', '10', 'best', 'steve', 'jobs', 'emails'],\n",
       " ['rt',\n",
       "  '@jpdesloges',\n",
       "  'aapl',\n",
       "  'stock',\n",
       "  'mini-flash',\n",
       "  'crash',\n",
       "  'today',\n",
       "  'aapl',\n",
       "  '#aapl']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets =[extract_words(i) for i in df_apple_tweets[0:50]['text'].values]\n",
    "tweets[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_doc_freq(corpus_words):\n",
    "    number_docs = len(corpus_words)\n",
    "    \n",
    "    document_count = {}\n",
    "\n",
    "    for document in corpus_words:\n",
    "        word_set = set(document)\n",
    "\n",
    "        for word in word_set:\n",
    "            document_count[word] = document_count.get(word, 0) + 1\n",
    "    \n",
    "    IDF = {}\n",
    "    \n",
    "    for word in document_count:\n",
    "        IDF[word] = np.log(number_docs/document_count[word])\n",
    "        \n",
    "    \n",
    "    return IDF\n",
    "\n",
    "def tf_idf(corpus_words):\n",
    "    IDF = inv_doc_freq(corpus_words)\n",
    "    \n",
    "    TFIDF = []\n",
    "    \n",
    "    for document in corpus_words:\n",
    "        TFIDF.append(Counter(document))\n",
    "    \n",
    "    for document in TFIDF:\n",
    "        for word in document:\n",
    "            document[word] = document[word]*IDF[word]\n",
    "            \n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = tf_idf(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'#aapl:the': 3.912023005428146,\n",
       "          '10': 3.912023005428146,\n",
       "          'best': 3.2188758248682006,\n",
       "          'steve': 3.912023005428146,\n",
       "          'jobs': 3.912023005428146,\n",
       "          'emails': 3.912023005428146}),\n",
       " Counter({'rt': 1.2039728043259361,\n",
       "          '@jpdesloges': 3.912023005428146,\n",
       "          'aapl': 6.437751649736401,\n",
       "          'stock': 2.8134107167600364,\n",
       "          'mini-flash': 3.2188758248682006,\n",
       "          'crash': 2.302585092994046,\n",
       "          'today': 2.5257286443082556,\n",
       "          '#aapl': 1.6094379124341003}),\n",
       " Counter({'cat': 3.912023005428146,\n",
       "          'chews': 3.912023005428146,\n",
       "          '@apple': 0.32850406697203605,\n",
       "          'cords': 3.912023005428146,\n",
       "          '#applesnob': 3.912023005428146})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDF[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(TFIDF):\n",
    "    words = set()\n",
    "    \n",
    "    for document in TFIDF:\n",
    "        words |= set(document.keys())\n",
    "    \n",
    "    word_list = list(words)\n",
    "    word_dict = dict(zip(word_list, range(len(word_list))))\n",
    "    \n",
    "    return word_dict, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict, word_list = build_vocabulary(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 287 words in our vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(word_dict)\n",
    "print(\"We have\", vocabulary_size, \"words in our vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['network',\n",
       " 'ios8',\n",
       " 'ever',\n",
       " 'store',\n",
       " 'bought',\n",
       " 'law',\n",
       " '8',\n",
       " 'tech',\n",
       " '#aapl:this',\n",
       " 'seizure']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_document_matrix(TFIDF, word_list, word_dict):\n",
    "    vocabulary_size = len(word_dict)\n",
    "    number_documents = len(TFIDF)\n",
    "    \n",
    "    TDM = np.zeros((vocabulary_size, number_documents))\n",
    "    \n",
    "    for doc in range(number_documents):\n",
    "        document = TFIDF[doc]\n",
    "        \n",
    "        for word in document.keys():\n",
    "            pos = word_dict[word]\n",
    "            \n",
    "            TDM[pos, doc] = document[word]\n",
    "            \n",
    "    return TDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset has:\n",
      "287 unique words\n",
      "50 documents\n"
     ]
    }
   ],
   "source": [
    "TDM = term_document_matrix(TFIDF, word_list, word_dict)\n",
    "print(\"Our dataset has:\\n%u unique words\\n%u documents\"%(TDM.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
